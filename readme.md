# ðŸŒ² **TreeFinder: A US-Scale Benchmark Dataset for Individual Tree Mortality Monitoring Using High-Resolution Aerial Imagery**

> **Accepted to NeurIPS 2025 Datasets & Benchmarks Track**
> Project page is available on NeurIPS: https://neurips.cc/virtual/2025/loc/san-diego/poster/121794.
> Datasets are available on Kaggle: https://www.kaggle.com/datasets/zhihaow/tree-finder.

Benchmarking deep learning models for **individual tree mortality detection** across the contiguous United States (CONUS).


---

## ðŸ§© Overview

**TreeFinder** provides a flexible PyTorch-based pipeline for training and evaluating semantic segmentation models on hand-labeled *dead-tree* imagery.  
It supports **custom dataset splits**, **config-driven experiments**, and **benchmarking under multiple generalization scenarios**, aligned with the official *TreeFinder dataset*.

---

## ðŸš€ Features

- **Multiple dataset splits** â€” random (80â€“10â€“10), state-based, and scenario-driven (climate / forest type)  
- **Consistent tile loading** â€” RGB, NIR, NDVI, and no-data mask handling  
- **Augmentations** â€” flips and 90Â° rotations for per-tile diversity  
- **Config-driven experiments** â€” all controlled via a single YAML file  
- **Model zoo** â€” U-Net, DeepLabV3+, ViT-Seg, SegFormer, Mask2Former, and DOFA  
- **Robust training loop** â€” masked BCE loss, early stopping, checkpointing, and LR scheduling  
- **Comprehensive evaluation** â€” IoU, F1, precision, recall, accuracy (micro/macro, all vs. positive-only)  
- **Automated logging** â€” loss curves, config dumps, and YAML summaries for every run  

---

## ðŸ§  Benchmark Models

| Model           | Type               | Description |
|-----------------|--------------------|-------------|
| **U-Net**       | CNN                | [ðŸ“„Paper](https://arxiv.org/abs/1505.04597) Classic encoderâ€“decoder architecture with skip connections. Trained from scratch as a baseline. |
| **DeepLabV3+**  | CNN                | [ðŸ“„Paper](https://arxiv.org/abs/1802.02611v3) Employs atrous spatial pyramid pooling with a ResNet-50 backbone. |
| **ViT-Seg**     | Vision Transformer | [ðŸ“„Paper](https://arxiv.org/abs/2010.11929) Patch-based transformer with a transposed-convolution decoder. |
| **SegFormer**   | Vision Transformer | [ðŸ“„Paper](https://arxiv.org/abs/2105.15203) Hierarchical transformer with efficient multi-scale feature fusion. |
| **Mask2Former** | Vision Transformer | [ðŸ“„Paper](https://arxiv.org/abs/2112.01527) Set prediction model using masked attention (Swin-T backbone). |
| **DOFA**        | Foundation Model   | [ðŸ“„Paper](https://arxiv.org/abs/2403.15356) Multimodal foundation model pretrained on multi-sensor remote-sensing imagery. |

All models are trained with consistent hyperparameters and evaluated under **cross-region**, **cross-climate**, and **cross-forest-type** generalization setups from the *TreeFinder benchmark*.

---

## ðŸ“ Repository Structure

```text
â”œâ”€â”€ main.py                   # Entrypoint: parse args, load config, run train & eval  
â”œâ”€â”€ configs/                  # YAML experiment configs  
â”‚   â”œâ”€â”€ debug.yaml  
â”‚   â””â”€â”€ benchmark.yaml  
â”œâ”€â”€ data_loader/              # Tile loading & split implementations  
â”‚   â”œâ”€â”€ __init__.py           # Dispatch get_dataloader(cfg)  
â”‚   â”œâ”€â”€ utils.py              # load_tile(), augment_tile()  
â”‚   â”œâ”€â”€ random_split.py  
â”‚   â”œâ”€â”€ by_state_split.py  
â”‚   â”œâ”€â”€ by_climate_split.py  
â”‚   â””â”€â”€ by_tree_split.py  
â”œâ”€â”€ models/                   # Model factory & builders  
â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”œâ”€â”€ unet.py  
â”‚   â”œâ”€â”€ deeplab.py  
â”‚   â”œâ”€â”€ vit.py  
â”‚   â”œâ”€â”€ segformer.py  
â”‚   â”œâ”€â”€ mask2former.py  
â”‚   â””â”€â”€ dofa/                 
â”œâ”€â”€ exps/                     # Training & evaluation loops  
â”‚   â”œâ”€â”€ train.py  
â”‚   â””â”€â”€ evaluate.py  
â””â”€â”€ utils/                    # Misc helpers (logging, config I/O, seed control)  
    â””â”€â”€ tools.py  
```

---

## âš™ï¸ Configuration and â–¶ï¸ Quickstart

All experiment parameters (model, optimizer, paths, augmentations, split type) are defined in YAML under `configs/`.  
For example:

```bash
python main.py --config configs/debug.yaml
```

---

## ðŸ“š Citation

If you use this repository or the **TreeFinder** dataset, please cite:

> **Zhihao Wang**, **Cooper Li**, **Ruichen Wang**, **Lei Ma**, **George Hurtt**, **Xiaowei Jia**, **Gengchen Mai**, **Zhili Li**, **Yiqun Xie**.  
> *TreeFinder: A US-Scale Benchmark Dataset for Individual Tree Mortality Monitoring Using High-Resolution Aerial Imagery.*  
> In *Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS)*, 2025.

<!-- ```bibtex
@inproceedings{wang2025treefinder,
  title     = {TreeFinder: A US-Scale Benchmark Dataset for Individual Tree Mortality Monitoring Using High-Resolution Aerial Imagery},
  author    = {Wang, Zhihao and Li, Cooper and Wang, Ruichen and Ma, Lei and Hurtt, George and Jia, Xiaowei and Mai, Gengchen and Li, Zhili and Xie, Yiqun},
  booktitle = {Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS 2025), Datasets and Benchmarks Track},
  year      = {2025}
}
``` -->

## ðŸ“¬ Contact

For questions or feedback, feel free to reach out:

- **Zhihao Wang** â€” [zhwang1@umd.edu](mailto:zhwang1@umd.edu)
- **Yiqun Xie** â€” [xie@umd.edu](mailto:xie@umd.edu)
